<!DOCTYPE html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <link rel="stylesheet" type="text/css" href="/lab2/css/style.css" />
  <link rel="shortcut icon" href="/lab2/img/icons/browser_icon.ico"/>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

</head><!DOCTYPE html>
<head>
  <script>
  function toggleMenu() {
      var x = document.getElementById("navmenu");
      if (x.className === "menu-items") {
          x.className += " responsive";
      } else {
          x.className = "menu-items";
      }
  }
  </script>
</head>
<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container-fluid">
    <a href="/lab2/">
      <img src="/lab2//img/icons/text-machine-White-min.png" hspace="20" class='navbar-logo'>
    </a>
    <div class="menu-items" id="navmenu">
      <div class="items-wrapper">
      <a href="/lab2/"> <span>Home</span></a>
      <a href="/lab2/projects/"><span>Projects</span></a>
      <a href="/lab2/events/"><span>Events</span></a>
      <a href="/lab2/people/"><span>People</span></a>
      <a href="/lab2/publications/"><span>Publications</span></a>
      <a href="https://text-machine-lab.github.io/blog/" target="_blank"><span>Blog<img class="blog-icon" src="/lab2/img/icons/external-link.png"></span></a>
      <a href="/lab2/contact/"><span>Contact</span></a>
      <a href="javascript:void(0);" class="icon" onclick="toggleMenu()">
          <i class="fa fa-bars"></i>
        </a>
      </div>
    </div>
  </div>
</nav>
<body>
  <article>
    <div class="article-container">
    
      <h3> NarrativeTime: Order and Timing of Events in Narrative Text </h3>
      <div class="author-container">
			<span class="author"><a href="/lab2/people/yuanliangmeng/">Yuanliang Meng</a></span>
			<span class="author"><a href="http://www.cs.uml.edu/~arum/" target="_blank">Anna Rumshisky</a></span>
			<span class="author"><a href="/lab2/people/alexeyromanov/">Alexey Romanov</a></span>
      </div>
      <div class="share-icons">
          <a href="https://github.com/text-machine-lab/TEA" target="_blank"> <img src="/lab2//img/icons/github.png"></a>
          <a href="mailto:ymeng@cs.uml.edu"><img src="/lab2//img/icons/email.png"></a>
      </div>
      <div class="buttons">
      </div>
      <p>This project has two stages so far:</p>
<p>(1) We propose to use a set of simple, uniform in architecture LSTM-based models to recover different kinds of temporal relations from text. Using the shortest dependency path between entities as input, the same architecture is implemented to extract intra-sentence, cross- sentence, and document creation time relations. A “double-checking” technique reverses entity pairs in classification, boosting the recall of positive cases and reducing misclassifications between opposite classes. An efficient pruning algorithm resolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our proposed technique outperforms state-of-the-art methods by a large margin. We also conduct intrinsic evaluation and post state-of-the-art results on Timebank-Dense.</p>
<p>(2) We propose a context-aware neural network model for temporal information extraction. This model has a uniform architecture for event-event, event-timex and timex-timex pairs. A Global Context Layer (GCL), inspired by Neural Turing Machine (NTM), stores processed temporal relations in narrative order, and retrieves them for use when relevant entities come in. Relations are then classified in context. The GCL model has long-term memory and attention mechanisms to resolve irregular long-distance dependencies that regular RNNs such as LSTM cannot recognize. It does not require any new input features, while outperforming the existing models in literature. To our knowledge it is also the first model to use NTM-like architecture to process the information from global context in discourse-scale natural text processing. We are going to release the source code in the future.</p>
<p><img src="/img/projects/temporalie_diagram.jpg" alt="Model diagram" title="Model diagram"></p>
<h4 id="fig1-model-diagram">Fig.1. Model diagram</h4>

      
     <h3>Publications</h3>
	<div class="publication">
			<img src="/lab2//img/icons/doc.png">
			<span class="author-container-pub">
			<span class="author pub">Y. Meng</span>
			<span class="author pub">A. Rumshisky</span>
			<span class="author pub">A. Romanov</span>
			</span>
			<span>
				Temporal Information Extraction for Question Answering Using Syntactic Dependencies in an LSTM-based Architecture.
			</span>
			<span>
				<em>Proceedings of EMNLP 2017.</em>
			</span>
  

		<div class="citing">
		<button onclick="window.open('http:\/\/aclweb.org\/anthology\/D17-1092.pdf','_blank');" type="button">PDF</button>

		<button type="button" data-toggle="collapse" data-target="#pub_2017">BibTeX</button>
		<div id="pub_2017" class="collapse">
        <pre><p>@inproceedings{meng_temporal_2017,
				author = &ldquo;Meng, Yuanliang and Rumshisky, Anna and Romanov, Alexey&rdquo;,
				address = &ldquo;Copenhagen, Denmark&rdquo;,
				title = &ldquo;Temporal {Information} {Extraction} for {Question} {Answering} {Using} {Syntactic} {Dependencies} in an {LSTM}-based {Architecture}&quot;,
				booktitle = &ldquo;Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}&quot;,
				publisher = &ldquo;Association for Computational Linguistics&rdquo;,
				year = &ldquo;2017&rdquo;,
				pages = &ldquo;887&ndash;896&rdquo;
			}</p>
		</pre>
        </div>
    
		</div>
	</div>

          

    <div class="publication">
		<img src="/lab2//img/icons/doc.png">
		<span class="author-container-pub">
		<span class="author pub">Y. Meng</span>
		<span class="author pub">A. Rumshisky</span>
		</span>
		<span>
			Context-Aware Neural Model for Temporal Information Extraction.
		</span>
		<span>
			<em>Proceedings of ACL 2018.</em>
		</span>

		<div class="citing">
			<button onclick="window.open('http:\/\/aclweb.org\/anthology\/P18-1049.pdf','_blank');" type="button">PDF</button>
			<button type="button" data-toggle="collapse" data-target="#pub_2018">BibTeX</button>
			<div id="pub_2018" class="collapse">
				<pre><p>@inproceedings{meng2018context,
				title={Context-Aware Neural Model for Temporal Information Extraction},
				author={Meng, Yuanliang and Rumshisky, Anna},
				booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
				volume={1},
				pages={527--536},
				year={2018}
				}</p>
				</pre>
			</div>
    
		</div>
	</div>

          
        
      
    </div>
  </article>
</body><!DOCTYPE html>
  <footer class="site-footer">
    <center><a href="https://www.uml.edu/" target="_blank">
      <img src="/lab2//img/icons/uml.png" alt="UML" height="42" ></center></a>
    <div class="container">
      <p class="powered-by">
        &copy Text Machine Lab. Powered by Hugo.
      </p>
    </div>
  </footer>
