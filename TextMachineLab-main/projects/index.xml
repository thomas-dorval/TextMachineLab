<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Text Machine Lab</title>
    <link>/lab2/projects/</link>
    <description>Recent content in Projects on Text Machine Lab</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="/lab2/projects/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Argument mining</title>
      <link>/lab2/projects/argumentmining/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/argumentmining/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CliNER: A Clinical Named Entity Recognition system</title>
      <link>/lab2/projects/cliner/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/cliner/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Conflict, bias, and sentiment in social media</title>
      <link>/lab2/projects/conflictbias/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/conflictbias/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CPA (Corpus Pattern Analysis)</title>
      <link>/lab2/projects/corpuspatternanalysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/corpuspatternanalysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fairness in Machine Learning</title>
      <link>/lab2/projects/fairness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/fairness/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Knowledge Evolution Project</title>
      <link>/lab2/projects/knowledgeevo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/knowledgeevo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Linguistic Diagnostics of Word Embeddings</title>
      <link>/lab2/projects/linguisticdiagnostics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/linguisticdiagnostics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NarrativeTime: Order and Timing of Events in Narrative Text</title>
      <link>/lab2/projects/narrativetime/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/narrativetime/</guid>
      <description>This project has two stages so far:
(1) We propose to use a set of simple, uniform in architecture LSTM-based models to recover different kinds of temporal relations from text. Using the shortest dependency path between entities as input, the same architecture is implemented to extract intra-sentence, cross- sentence, and document creation time relations. A “double-checking” technique reverses entity pairs in classification, boosting the recall of positive cases and reducing misclassifications between opposite classes.</description>
    </item>
    
    <item>
      <title>Normalization of Medical Concepts in Clinical Narrative</title>
      <link>/lab2/projects/conceptnorm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/conceptnorm/</guid>
      <description>Normalization maps clinical terms in medical notes to concepts in standardized medical vocabularies. To complement the traditional lexical transformation based approach, we propose a hybrid normalization system which incorporates a deep learning model to capture semantic similarity between different surface expressions of the same concept. When evaluating our system against the mentions which may be normalized to existing concepts in the ShARe/CLEF eHealth 2013 dataset, our hybrid system achieves 90.6% in accuracy and outperforms a strong exact match + edit distance baseline by 2.</description>
    </item>
    
    <item>
      <title>QuAIL</title>
      <link>/lab2/projects/quail/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/quail/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Revealing the dark secrets of BERT</title>
      <link>/lab2/projects/bert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/bert/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RuSentiment: An Enriched Sentiment Analysis Dataset for Social Media in Russian</title>
      <link>/lab2/projects/rusentiment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/rusentiment/</guid>
      <description>We present RuSentiment, a new dataset for sentiment analysis of social media posts in Russian. RuSentiment is currently the largest in its class for Russian, with 30,521 posts annotated with Fleiss&amp;rsquo; kappa of 0.58 (3 annotations per post). To diversify the dataset, 6,749 posts were pre-selected with an active learning-style strategy. We report baseline classification results, and we also release the best-performing embeddings trained on 3.2B tokens of Russian VKontakte posts.</description>
    </item>
    
    <item>
      <title>TwitterHawk - a Twitter Sentiment Analysis System</title>
      <link>/lab2/projects/twitterhawk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/lab2/projects/twitterhawk/</guid>
      <description>TwitterHawk is an open-source natural language processing system for Twitter sentiment analysis. This system was developed for the SemEval-2015 Task 10: Sentiment Analysis in Twitter. The system placed 1st in topic-based sentiment classification (Subtask C), and ranked 6th out of 40 in identifying the sentiment of sarcastic tweets (for Subtask B). The system also placed 5th/11 for Subtask A (sentiment of a tweet&#39;s sub-phrase), 10th/40 for Subtask B (sentiment of a full tweet), and 3rd/6 for Subtask D (summarization of Subtask C).</description>
    </item>
    
  </channel>
</rss>